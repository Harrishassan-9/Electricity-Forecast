{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f39d80-075f-42b9-b335-ce9ce35df23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis for dallas_with_demand.csv:\n",
      "Number of columns: 22\n",
      "Common columns with dallas.csv (20): ['apparentTemperature', 'cloudCover', 'demand', 'dewPoint', 'humidity', 'icon', 'ozone', 'precipAccumulation', 'precipIntensity', 'precipProbability', 'precipType', 'pressure', 'summary', 'temperature', 'time', 'uvIndex', 'visibility', 'windBearing', 'windGust', 'windSpeed']\n",
      "Columns missing from dallas.csv (0): []\n",
      "Extra columns not in dallas.csv (2): ['city', 'datetime']\n",
      "\n",
      "Analysis for houston_with_demand.csv:\n",
      "Number of columns: 22\n",
      "Common columns with dallas.csv (20): ['apparentTemperature', 'cloudCover', 'demand', 'dewPoint', 'humidity', 'icon', 'ozone', 'precipAccumulation', 'precipIntensity', 'precipProbability', 'precipType', 'pressure', 'summary', 'temperature', 'time', 'uvIndex', 'visibility', 'windBearing', 'windGust', 'windSpeed']\n",
      "Columns missing from dallas.csv (0): []\n",
      "Extra columns not in dallas.csv (2): ['city', 'datetime']\n",
      "\n",
      "Analysis for la_with_demand.csv:\n",
      "Number of columns: 21\n",
      "Common columns with dallas.csv (19): ['apparentTemperature', 'cloudCover', 'demand', 'dewPoint', 'humidity', 'icon', 'ozone', 'precipIntensity', 'precipProbability', 'precipType', 'pressure', 'summary', 'temperature', 'time', 'uvIndex', 'visibility', 'windBearing', 'windGust', 'windSpeed']\n",
      "Columns missing from dallas.csv (1): ['precipAccumulation']\n",
      "Extra columns not in dallas.csv (2): ['city', 'datetime']\n",
      "\n",
      "Analysis for nyc_with_demand.csv:\n",
      "Number of columns: 22\n",
      "Common columns with dallas.csv (20): ['apparentTemperature', 'cloudCover', 'demand', 'dewPoint', 'humidity', 'icon', 'ozone', 'precipAccumulation', 'precipIntensity', 'precipProbability', 'precipType', 'pressure', 'summary', 'temperature', 'time', 'uvIndex', 'visibility', 'windBearing', 'windGust', 'windSpeed']\n",
      "Columns missing from dallas.csv (0): []\n",
      "Extra columns not in dallas.csv (2): ['city', 'datetime']\n",
      "\n",
      "Analysis for philadelphia_with_demand.csv:\n",
      "Number of columns: 22\n",
      "Common columns with dallas.csv (20): ['apparentTemperature', 'cloudCover', 'demand', 'dewPoint', 'humidity', 'icon', 'ozone', 'precipAccumulation', 'precipIntensity', 'precipProbability', 'precipType', 'pressure', 'summary', 'temperature', 'time', 'uvIndex', 'visibility', 'windBearing', 'windGust', 'windSpeed']\n",
      "Columns missing from dallas.csv (0): []\n",
      "Extra columns not in dallas.csv (2): ['city', 'datetime']\n",
      "\n",
      "Analysis for phoenix_with_demand.csv:\n",
      "Number of columns: 22\n",
      "Common columns with dallas.csv (20): ['apparentTemperature', 'cloudCover', 'demand', 'dewPoint', 'humidity', 'icon', 'ozone', 'precipAccumulation', 'precipIntensity', 'precipProbability', 'precipType', 'pressure', 'summary', 'temperature', 'time', 'uvIndex', 'visibility', 'windBearing', 'windGust', 'windSpeed']\n",
      "Columns missing from dallas.csv (0): []\n",
      "Extra columns not in dallas.csv (2): ['city', 'datetime']\n",
      "\n",
      "Analysis for san_antonio_with_demand.csv:\n",
      "Number of columns: 22\n",
      "Common columns with dallas.csv (20): ['apparentTemperature', 'cloudCover', 'demand', 'dewPoint', 'humidity', 'icon', 'ozone', 'precipAccumulation', 'precipIntensity', 'precipProbability', 'precipType', 'pressure', 'summary', 'temperature', 'time', 'uvIndex', 'visibility', 'windBearing', 'windGust', 'windSpeed']\n",
      "Columns missing from dallas.csv (0): []\n",
      "Extra columns not in dallas.csv (2): ['city', 'datetime']\n",
      "\n",
      "Analysis for san_diego_with_demand.csv:\n",
      "Number of columns: 21\n",
      "Common columns with dallas.csv (19): ['apparentTemperature', 'cloudCover', 'demand', 'dewPoint', 'humidity', 'icon', 'ozone', 'precipIntensity', 'precipProbability', 'precipType', 'pressure', 'summary', 'temperature', 'time', 'uvIndex', 'visibility', 'windBearing', 'windGust', 'windSpeed']\n",
      "Columns missing from dallas.csv (1): ['precipAccumulation']\n",
      "Extra columns not in dallas.csv (2): ['city', 'datetime']\n",
      "\n",
      "Analysis for san_jose_with_demand.csv:\n",
      "Number of columns: 21\n",
      "Common columns with dallas.csv (19): ['apparentTemperature', 'cloudCover', 'demand', 'dewPoint', 'humidity', 'icon', 'ozone', 'precipIntensity', 'precipProbability', 'precipType', 'pressure', 'summary', 'temperature', 'time', 'uvIndex', 'visibility', 'windBearing', 'windGust', 'windSpeed']\n",
      "Columns missing from dallas.csv (1): ['precipAccumulation']\n",
      "Extra columns not in dallas.csv (2): ['city', 'datetime']\n",
      "\n",
      "Analysis for seattle_with_demand.csv:\n",
      "Number of columns: 22\n",
      "Common columns with dallas.csv (20): ['apparentTemperature', 'cloudCover', 'demand', 'dewPoint', 'humidity', 'icon', 'ozone', 'precipAccumulation', 'precipIntensity', 'precipProbability', 'precipType', 'pressure', 'summary', 'temperature', 'time', 'uvIndex', 'visibility', 'windBearing', 'windGust', 'windSpeed']\n",
      "Columns missing from dallas.csv (0): []\n",
      "Extra columns not in dallas.csv (2): ['city', 'datetime']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "csv_dir = r\"C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\"\n",
    "\n",
    "# List of city CSV files\n",
    "cities = [\n",
    "    \"la_with_demand\", \"nyc_with_demand\", \"philadelphia_with_demand\", \"phoenix_with_demand\", \"san_antonio_with_demand\", \n",
    "    \"san_diego_with_demand\", \"san_jose_with_demand\", \"seattle_with_demand\"\n",
    "]\n",
    "# Include dallas and houston for completeness\n",
    "all_cities = [\"dallas_with_demand\", \"houston_with_demand\"] + cities\n",
    "\n",
    "# Reference columns from dallas.csv\n",
    "reference_columns = {\n",
    "    'time', 'summary', 'icon', 'precipIntensity', 'precipProbability', 'temperature', \n",
    "    'apparentTemperature', 'dewPoint', 'humidity', 'pressure', 'windSpeed', 'windGust', \n",
    "    'windBearing', 'cloudCover', 'uvIndex', 'visibility', 'precipType', 'ozone', \n",
    "    'precipAccumulation','demand'\n",
    "}\n",
    "\n",
    "# Dictionary to store columns for each CSV file\n",
    "columns_dict = {}\n",
    "\n",
    "# Read the columns of each CSV file\n",
    "for city in all_cities:\n",
    "    file_path = os.path.join(csv_dir, f\"{city}.csv\")\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: {file_path} does not exist.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Read only the first row to get column names\n",
    "        df = pd.read_csv(file_path, nrows=0)\n",
    "        columns_dict[city] = set(df.columns)  # Store columns as a set\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Compare columns with dallas.csv\n",
    "if not columns_dict:\n",
    "    print(\"No valid CSV files were found.\")\n",
    "else:\n",
    "    for city in columns_dict:\n",
    "        current_columns = columns_dict[city]\n",
    "        \n",
    "        # Find common, missing, and extra columns\n",
    "        common_columns = current_columns & reference_columns  # Intersection\n",
    "        missing_columns = reference_columns - current_columns  # In dallas.csv but not in current\n",
    "        extra_columns = current_columns - reference_columns  # In current but not in dallas.csv\n",
    "        \n",
    "        print(f\"\\nAnalysis for {city}.csv:\")\n",
    "        print(f\"Number of columns: {len(current_columns)}\")\n",
    "        print(f\"Common columns with dallas.csv ({len(common_columns)}): {sorted(common_columns)}\")\n",
    "        print(f\"Columns missing from dallas.csv ({len(missing_columns)}): {sorted(missing_columns)}\")\n",
    "        print(f\"Extra columns not in dallas.csv ({len(extra_columns)}): {sorted(extra_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f22e43ef-aae2-4e75-b959-02db042a2c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'precipAccumulation' column in la_with_demand.csv\n",
      "Removed 'precipAccumulation' from nyc_with_demand.csv\n",
      "Removed 'precipAccumulation' from philadelphia_with_demand.csv\n",
      "Removed 'precipAccumulation' from phoenix_with_demand.csv\n",
      "Removed 'precipAccumulation' from san_antonio_with_demand.csv\n",
      "No 'precipAccumulation' column in san_diego_with_demand.csv\n",
      "No 'precipAccumulation' column in san_jose_with_demand.csv\n",
      "Removed 'precipAccumulation' from seattle_with_demand.csv\n",
      "All CSV files have the same columns:\n",
      "['apparentTemperature', 'city', 'cloudCover', 'datetime', 'demand', 'dewPoint', 'humidity', 'icon', 'ozone', 'precipIntensity', 'precipProbability', 'precipType', 'pressure', 'summary', 'temperature', 'time', 'uvIndex', 'visibility', 'windBearing', 'windGust', 'windSpeed']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "csv_dir = r\"C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\"\n",
    "\n",
    "# List of city CSV files\n",
    "cities = [\n",
    "    \"la_with_demand\", \"nyc_with_demand\", \"philadelphia_with_demand\", \"phoenix_with_demand\", \"san_antonio_with_demand\", \n",
    "    \"san_diego_with_demand\", \"san_jose_with_demand\", \"seattle_with_demand\"\n",
    "]\n",
    "# Include dallas and houston for completeness\n",
    "all_cities = [\"dallas_with_demand\", \"houston_with_demand\"] + cities\n",
    "\n",
    "# Step 1: Remove 'precipAccumulation' column from all CSV files\n",
    "for city in cities:\n",
    "    file_path = os.path.join(csv_dir, f\"{city}.csv\")\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: {file_path} does not exist.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Check if 'precipAccumulation' column exists and remove it\n",
    "        if 'precipAccumulation' in df.columns:\n",
    "            df = df.drop(columns=['precipAccumulation'])\n",
    "            # Save the modified CSV back to the same file\n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(f\"Removed 'precipAccumulation' from {city}.csv\")\n",
    "        else:\n",
    "            print(f\"No 'precipAccumulation' column in {city}.csv\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# Step 2: Check if all CSV files have the same columns\n",
    "columns_dict = {}\n",
    "\n",
    "# Read the columns of each CSV file\n",
    "for city in cities:\n",
    "    file_path = os.path.join(csv_dir, f\"{city}.csv\")\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: {file_path} does not exist.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Read only the first row to get column names\n",
    "        df = pd.read_csv(file_path, nrows=0)\n",
    "        columns_dict[city] = set(df.columns)  # Store columns as a set\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Compare columns across all CSV files\n",
    "if not columns_dict:\n",
    "    print(\"No valid CSV files were found.\")\n",
    "else:\n",
    "    # Get the columns of the first city as reference\n",
    "    reference_city = next(iter(columns_dict))\n",
    "    reference_columns = columns_dict[reference_city]\n",
    "    \n",
    "    all_same = True\n",
    "    for city, columns in columns_dict.items():\n",
    "        if columns != reference_columns:\n",
    "            all_same = False\n",
    "            print(f\"{city}.csv has different columns.\")\n",
    "            print(f\"Columns in {reference_city}.csv: {sorted(reference_columns)}\")\n",
    "            print(f\"Columns in {city}.csv: {sorted(columns)}\")\n",
    "    \n",
    "    if all_same:\n",
    "        print(\"All CSV files have the same columns:\")\n",
    "        print(sorted(reference_columns))\n",
    "    else:\n",
    "        print(\"Some CSV files have different columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4490c263-d3dc-4e02-988d-51f21bd482d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed la_with_demand.csv with 16526 rows\n",
      "Processed nyc_with_demand.csv with 16503 rows\n",
      "Processed philadelphia_with_demand.csv with 16503 rows\n",
      "Processed phoenix_with_demand.csv with 15950 rows\n",
      "Processed san_antonio_with_demand.csv with 16503 rows\n",
      "Processed san_diego_with_demand.csv with 16526 rows\n",
      "Processed san_jose_with_demand.csv with 16526 rows\n",
      "Processed seattle_with_demand.csv with 15950 rows\n",
      "\n",
      "Combined dataset saved to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\\Combined_Data.csv\n",
      "Total rows in combined dataset: 130987\n",
      "Columns in combined dataset: ['City', 'time', 'summary', 'icon', 'precipIntensity', 'precipProbability', 'temperature', 'apparentTemperature', 'dewPoint', 'humidity', 'pressure', 'windSpeed', 'windGust', 'windBearing', 'cloudCover', 'uvIndex', 'visibility', 'precipType', 'ozone', 'datetime', 'city', 'demand']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "csv_dir = r\"C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\"\n",
    "\n",
    "# List of city CSV files\n",
    "cities = [\n",
    "    \"la_with_demand\", \"nyc_with_demand\", \"philadelphia_with_demand\", \"phoenix_with_demand\", \"san_antonio_with_demand\", \n",
    "    \"san_diego_with_demand\", \"san_jose_with_demand\", \"seattle_with_demand\"\n",
    "]\n",
    "# Include dallas and houston for completeness\n",
    "all_cities = [\"dallas_with_demand\", \"houston_with_demand\"] + cities\n",
    "\n",
    "# List to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Read each CSV file and add the 'City' column\n",
    "for city in cities:\n",
    "    file_path = os.path.join(csv_dir, f\"{city}.csv\")\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: {file_path} does not exist.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Add 'City' column with the city name\n",
    "        df.insert(0, 'City', city.capitalize())  # Capitalize for consistency (e.g., 'Dallas')\n",
    "        \n",
    "        # Append to the list of DataFrames\n",
    "        dfs.append(df)\n",
    "        print(f\"Processed {city}.csv with {len(df)} rows\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Combine all DataFrames\n",
    "if not dfs:\n",
    "    print(\"No valid CSV files were found.\")\n",
    "else:\n",
    "    # Concatenate all DataFrames\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Define the output file path\n",
    "    output_file = os.path.join(csv_dir, \"Combined_Data.csv\")\n",
    "    \n",
    "    # Save the combined DataFrame to a new CSV file\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nCombined dataset saved to {output_file}\")\n",
    "    print(f\"Total rows in combined dataset: {len(combined_df)}\")\n",
    "    print(f\"Columns in combined dataset: {list(combined_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97749464-6ce8-4941-b728-631296654b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>time</th>\n",
       "      <th>summary</th>\n",
       "      <th>icon</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>precipProbability</th>\n",
       "      <th>temperature</th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>...</th>\n",
       "      <th>windGust</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>cloudCover</th>\n",
       "      <th>uvIndex</th>\n",
       "      <th>visibility</th>\n",
       "      <th>precipType</th>\n",
       "      <th>ozone</th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>1530432000</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65.16</td>\n",
       "      <td>65.16</td>\n",
       "      <td>58.62</td>\n",
       "      <td>0.79</td>\n",
       "      <td>...</td>\n",
       "      <td>3.95</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-01 08:00:00</td>\n",
       "      <td>la</td>\n",
       "      <td>10681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>1530435600</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.58</td>\n",
       "      <td>64.58</td>\n",
       "      <td>58.23</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>4.21</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-01 09:00:00</td>\n",
       "      <td>la</td>\n",
       "      <td>10197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>1530439200</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.46</td>\n",
       "      <td>64.46</td>\n",
       "      <td>57.87</td>\n",
       "      <td>0.79</td>\n",
       "      <td>...</td>\n",
       "      <td>4.04</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-01 10:00:00</td>\n",
       "      <td>la</td>\n",
       "      <td>9776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>1530442800</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.19</td>\n",
       "      <td>64.19</td>\n",
       "      <td>57.96</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>3.81</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-01 11:00:00</td>\n",
       "      <td>la</td>\n",
       "      <td>9508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>1530446400</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.09</td>\n",
       "      <td>64.09</td>\n",
       "      <td>57.84</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>3.81</td>\n",
       "      <td>181.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-01 12:00:00</td>\n",
       "      <td>la</td>\n",
       "      <td>9431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130982</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>1587870000</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.03</td>\n",
       "      <td>55.60</td>\n",
       "      <td>55.60</td>\n",
       "      <td>42.07</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>15.31</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000</td>\n",
       "      <td>rain</td>\n",
       "      <td>338.3</td>\n",
       "      <td>2020-04-26 03:00:00</td>\n",
       "      <td>seattle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130983</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>1587873600</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.02</td>\n",
       "      <td>53.87</td>\n",
       "      <td>53.87</td>\n",
       "      <td>42.79</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>14.36</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000</td>\n",
       "      <td>rain</td>\n",
       "      <td>339.5</td>\n",
       "      <td>2020-04-26 04:00:00</td>\n",
       "      <td>seattle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130984</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>1587877200</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>52.54</td>\n",
       "      <td>52.54</td>\n",
       "      <td>43.22</td>\n",
       "      <td>0.70</td>\n",
       "      <td>...</td>\n",
       "      <td>13.09</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.7</td>\n",
       "      <td>2020-04-26 05:00:00</td>\n",
       "      <td>seattle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130985</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>1587880800</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.02</td>\n",
       "      <td>51.02</td>\n",
       "      <td>43.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>11.76</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341.6</td>\n",
       "      <td>2020-04-26 06:00:00</td>\n",
       "      <td>seattle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130986</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>1587884400</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.03</td>\n",
       "      <td>49.80</td>\n",
       "      <td>47.88</td>\n",
       "      <td>43.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>10.89</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000</td>\n",
       "      <td>rain</td>\n",
       "      <td>350.9</td>\n",
       "      <td>2020-04-26 07:00:00</td>\n",
       "      <td>seattle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130987 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       City        time        summary                 icon  \\\n",
       "0            La_with_demand  1530432000       Overcast               cloudy   \n",
       "1            La_with_demand  1530435600       Overcast               cloudy   \n",
       "2            La_with_demand  1530439200       Overcast               cloudy   \n",
       "3            La_with_demand  1530442800       Overcast               cloudy   \n",
       "4            La_with_demand  1530446400       Overcast               cloudy   \n",
       "...                     ...         ...            ...                  ...   \n",
       "130982  Seattle_with_demand  1587870000  Mostly Cloudy    partly-cloudy-day   \n",
       "130983  Seattle_with_demand  1587873600  Mostly Cloudy  partly-cloudy-night   \n",
       "130984  Seattle_with_demand  1587877200  Mostly Cloudy  partly-cloudy-night   \n",
       "130985  Seattle_with_demand  1587880800  Mostly Cloudy  partly-cloudy-night   \n",
       "130986  Seattle_with_demand  1587884400  Mostly Cloudy  partly-cloudy-night   \n",
       "\n",
       "        precipIntensity  precipProbability  temperature  apparentTemperature  \\\n",
       "0                0.0000               0.00        65.16                65.16   \n",
       "1                0.0000               0.00        64.58                64.58   \n",
       "2                0.0000               0.00        64.46                64.46   \n",
       "3                0.0000               0.00        64.19                64.19   \n",
       "4                0.0000               0.00        64.09                64.09   \n",
       "...                 ...                ...          ...                  ...   \n",
       "130982           0.0017               0.03        55.60                55.60   \n",
       "130983           0.0008               0.02        53.87                53.87   \n",
       "130984           0.0000               0.00        52.54                52.54   \n",
       "130985           0.0000               0.00        51.02                51.02   \n",
       "130986           0.0017               0.03        49.80                47.88   \n",
       "\n",
       "        dewPoint  humidity  ...  windGust  windBearing  cloudCover  uvIndex  \\\n",
       "0          58.62      0.79  ...      3.95        193.0        0.88      0.0   \n",
       "1          58.23      0.80  ...      4.21        185.0        0.92      0.0   \n",
       "2          57.87      0.79  ...      4.04        175.0        0.99      0.0   \n",
       "3          57.96      0.80  ...      3.81        182.0        1.00      0.0   \n",
       "4          57.84      0.80  ...      3.81        181.0        1.00      0.0   \n",
       "...          ...       ...  ...       ...          ...         ...      ...   \n",
       "130982     42.07      0.60  ...     15.31        219.0        0.72      0.0   \n",
       "130983     42.79      0.66  ...     14.36        212.0        0.76      0.0   \n",
       "130984     43.22      0.70  ...     13.09        208.0        0.70      0.0   \n",
       "130985     43.48      0.75  ...     11.76        203.0        0.61      0.0   \n",
       "130986     43.80      0.80  ...     10.89        199.0        0.62      0.0   \n",
       "\n",
       "        visibility  precipType  ozone             datetime     city   demand  \n",
       "0            9.777         NaN    NaN  2018-07-01 08:00:00       la  10681.0  \n",
       "1            9.778         NaN    NaN  2018-07-01 09:00:00       la  10197.0  \n",
       "2            9.782         NaN    NaN  2018-07-01 10:00:00       la   9776.0  \n",
       "3            9.108         NaN    NaN  2018-07-01 11:00:00       la   9508.0  \n",
       "4            9.709         NaN    NaN  2018-07-01 12:00:00       la   9431.0  \n",
       "...            ...         ...    ...                  ...      ...      ...  \n",
       "130982      10.000        rain  338.3  2020-04-26 03:00:00  seattle      NaN  \n",
       "130983      10.000        rain  339.5  2020-04-26 04:00:00  seattle      NaN  \n",
       "130984      10.000         NaN  340.7  2020-04-26 05:00:00  seattle      NaN  \n",
       "130985      10.000         NaN  341.6  2020-04-26 06:00:00  seattle      NaN  \n",
       "130986      10.000        rain  350.9  2020-04-26 07:00:00  seattle      NaN  \n",
       "\n",
       "[130987 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the combined CSV file\n",
    "csv_path = r\"C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\\Combined_Data.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df\n",
    "#print(\"\\nDataFrame Info:\")\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b85b4d62-94f9-4cca-b9d0-ab14fafe0429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = pd.to_datetime(df['time'], unit='s', utc=True)\n",
    "# Create new columns for datetime components\n",
    "df['Year'] = df['time'].dt.year\n",
    "df['Month'] = df['time'].dt.month\n",
    "df['Day'] = df['time'].dt.day\n",
    "df['Hour'] = df['time'].dt.hour\n",
    "df['Minute'] = df['time'].dt.minute\n",
    "df['Second'] = df['time'].dt.second\n",
    "df = df.drop(columns=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2066b304-78f3-4cbb-8f07-8ff39bb21fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df Saved into csv\n"
     ]
    }
   ],
   "source": [
    "csv_dir = r\"C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\"\n",
    "output_file = os.path.join(csv_dir, \"Partially_Cleaned_Combined_Data.csv\")\n",
    "df.to_csv(output_file, index=False)\n",
    "print(\"Df Saved into csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9304ba54-e9ee-4cef-a6e3-e7ef313fe506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       0\n",
       "summary                  222\n",
       "icon                     223\n",
       "precipIntensity          184\n",
       "precipProbability        184\n",
       "temperature                8\n",
       "apparentTemperature        8\n",
       "dewPoint                   0\n",
       "humidity                   8\n",
       "pressure                  39\n",
       "windSpeed                 41\n",
       "windGust                 167\n",
       "windBearing               42\n",
       "cloudCover               192\n",
       "uvIndex                  141\n",
       "visibility               137\n",
       "precipType             73963\n",
       "ozone                  16179\n",
       "datetime                   0\n",
       "city                       0\n",
       "demand                 10117\n",
       "Year                       0\n",
       "Month                      0\n",
       "Day                        0\n",
       "Hour                       0\n",
       "Minute                     0\n",
       "Second                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06e54409-f333-4b32-addf-110681360042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"Partially_Cleaned_Combined_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96c4b148-204e-41de-b6c1-c062d30343ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    'precipIntensity', 'precipProbability', 'temperature', 'apparentTemperature',\n",
    "    'dewPoint', 'humidity', 'pressure', 'windSpeed', 'windGust', 'windBearing',\n",
    "    'cloudCover', 'uvIndex', 'visibility', 'ozone', 'Year', 'Month', 'Day',\n",
    "    'Hour', 'Minute', 'Second','demand'\n",
    "]\n",
    "\n",
    "# Fill missing values in numerical columns with their mean\n",
    "for col in numerical_columns:\n",
    "    df[col] = df[col].fillna(df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "990b7ea8-fc75-424c-9c67-c3ab24b6b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['summary', 'icon']\n",
    "\n",
    "# Fill missing values in the specified categorical columns with their mode\n",
    "for col in categorical_columns:\n",
    "    mode_value = df[col].mode()[0]  # Get the most frequent value (mode)\n",
    "    df[col] = df[col].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b10cda88-5c9a-4dc1-a49e-396dd3c74a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       0\n",
       "summary                    0\n",
       "icon                       0\n",
       "precipIntensity            0\n",
       "precipProbability          0\n",
       "temperature                0\n",
       "apparentTemperature        0\n",
       "dewPoint                   0\n",
       "humidity                   0\n",
       "pressure                   0\n",
       "windSpeed                  0\n",
       "windGust                   0\n",
       "windBearing                0\n",
       "cloudCover                 0\n",
       "uvIndex                    0\n",
       "visibility                 0\n",
       "precipType             73963\n",
       "ozone                      0\n",
       "datetime                   0\n",
       "city                       0\n",
       "demand                     0\n",
       "Year                       0\n",
       "Month                      0\n",
       "Day                        0\n",
       "Hour                       0\n",
       "Minute                     0\n",
       "Second                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3050b71b-2ebe-4f4c-871f-656b263a8b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 445 entries with temperature < 34.5°F and precipType = 'rain'.\n"
     ]
    }
   ],
   "source": [
    "low_temp_rain = df[(df['temperature'] < 34.5) & (df['precipType'] == 'rain')]\n",
    "\n",
    "# Output the result\n",
    "if not low_temp_rain.empty:\n",
    "    print(f\"Found {len(low_temp_rain)} entries with temperature < 34.5°F and precipType = 'rain'.\")\n",
    "else:\n",
    "    print(\"No entries with temperature < 34.5°F and precipType = 'rain' found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e946c7a-a0e2-4443-b26f-d33f1a6aea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This means there are 535 instances in your dataset where the temperature is below 34.5°F and the precipitation type is recorded as 'rain'. \n",
    "# It suggests rain can occur at these low temperatures, which is unusual as temperatures below 34.5°F often favor snow or sleet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4547aba7-d0f0-429a-84c4-55c99557a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['temperature'] < 34.5) & (df['precipType'].isna()), 'precipType'] = 'snow'\n",
    "df.loc[(df['temperature'] >= 34.5) & (df['precipType'].isna()), 'precipType'] = 'rain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bb30a4c-993b-4dc8-9aae-b050f1e8ab85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records flagged as anomaly or outlier: 30804\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Step 1: Drop unnecessary columns\n",
    "df.drop(['Minute', 'Second'], axis=1, inplace=True)\n",
    "\n",
    "# Step 2: Create datetime column\n",
    "df['datetime'] = pd.to_datetime(df[['Year', 'Month', 'Day', 'Hour']])\n",
    "\n",
    "# Step 3: Extract time-based features\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "df['season'] = df['Month'] % 12 // 3 + 1  # 1: Winter, 2: Spring, 3: Summer, 4: Fall\n",
    "\n",
    "# Step 4: Normalize continuous variables\n",
    "exclude = ['Year', 'Month', 'Day', 'Hour', 'day_of_week', 'season']\n",
    "continuous_cols = df.select_dtypes(include=[np.number]).columns.difference(exclude)\n",
    "scaler = MinMaxScaler()\n",
    "df[continuous_cols] = scaler.fit_transform(df[continuous_cols])\n",
    "\n",
    "# Step 5: Compute daily summary statistics\n",
    "daily_summary = df.groupby(['Year', 'Month', 'Day'])[continuous_cols].agg(['mean', 'max', 'min'])\n",
    "\n",
    "# Step 6: Outlier detection (Z-score & IQR) — only flag\n",
    "def detect_outliers(data, threshold_z=3):\n",
    "    outlier_flags = pd.Series([0] * len(data), index=data.index)\n",
    "    for col in data.select_dtypes(include=[np.number]).columns:\n",
    "        z = np.abs((data[col] - data[col].mean()) / data[col].std())\n",
    "        Q1 = data[col].quantile(0.15)\n",
    "        Q3 = data[col].quantile(0.85)\n",
    "        IQR = Q3 - Q1\n",
    "        iqr_mask = (data[col] >= Q1 - 1.5 * IQR) & (data[col] <= Q3 + 1.5 * IQR)\n",
    "        z_mask = z < threshold_z\n",
    "        combined_mask = ~(iqr_mask & z_mask)  # if any condition fails, it's an outlier\n",
    "        outlier_flags |= combined_mask.astype(int)\n",
    "    return outlier_flags\n",
    "\n",
    "df['outlier_flag'] = detect_outliers(df)\n",
    "\n",
    "# Step 7: Isolation Forest anomaly detection\n",
    "numerical_data = df.select_dtypes(include=[np.number])\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "anomaly_labels = iso_forest.fit_predict(numerical_data)\n",
    "df['anomaly_flag'] = (anomaly_labels == -1).astype(int)\n",
    "\n",
    "# Step 8: Combine both flags\n",
    "df['Flagged_anomaly_outlier'] = df[['outlier_flag', 'anomaly_flag']].max(axis=1)\n",
    "\n",
    "# Optional: Report number of flagged records\n",
    "total_flagged = df['Flagged_anomaly_outlier'].sum()\n",
    "print(f\"Total records flagged as anomaly or outlier: {total_flagged}\")\n",
    "\n",
    "# Final columns to keep (if needed)\n",
    "# df_final = df.drop(columns=['outlier_flag', 'anomaly_flag'])  # Uncomment to drop individual flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "957a4449-58c7-4147-a72e-e8b78e659db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>summary</th>\n",
       "      <th>icon</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>precipProbability</th>\n",
       "      <th>temperature</th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>demand</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>season</th>\n",
       "      <th>outlier_flag</th>\n",
       "      <th>anomaly_flag</th>\n",
       "      <th>Flagged_anomaly_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.557537</td>\n",
       "      <td>0.624395</td>\n",
       "      <td>0.858447</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.575804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116990</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.552286</td>\n",
       "      <td>0.619937</td>\n",
       "      <td>0.855708</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.571210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112280</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.551200</td>\n",
       "      <td>0.619015</td>\n",
       "      <td>0.853181</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.568147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108183</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.548755</td>\n",
       "      <td>0.616940</td>\n",
       "      <td>0.853813</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.571210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105575</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.547850</td>\n",
       "      <td>0.616171</td>\n",
       "      <td>0.852970</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.578867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104825</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130982</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.470982</td>\n",
       "      <td>0.550918</td>\n",
       "      <td>0.742241</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.643185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130983</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.455319</td>\n",
       "      <td>0.537622</td>\n",
       "      <td>0.747297</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.650842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130984</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.443278</td>\n",
       "      <td>0.527400</td>\n",
       "      <td>0.750316</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.661562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130985</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.429516</td>\n",
       "      <td>0.515717</td>\n",
       "      <td>0.752142</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.666156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130986</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.418470</td>\n",
       "      <td>0.491584</td>\n",
       "      <td>0.754388</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.667688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130987 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       City        summary                 icon  \\\n",
       "0            La_with_demand       Overcast               cloudy   \n",
       "1            La_with_demand       Overcast               cloudy   \n",
       "2            La_with_demand       Overcast               cloudy   \n",
       "3            La_with_demand       Overcast               cloudy   \n",
       "4            La_with_demand       Overcast               cloudy   \n",
       "...                     ...            ...                  ...   \n",
       "130982  Seattle_with_demand  Mostly Cloudy    partly-cloudy-day   \n",
       "130983  Seattle_with_demand  Mostly Cloudy  partly-cloudy-night   \n",
       "130984  Seattle_with_demand  Mostly Cloudy  partly-cloudy-night   \n",
       "130985  Seattle_with_demand  Mostly Cloudy  partly-cloudy-night   \n",
       "130986  Seattle_with_demand  Mostly Cloudy  partly-cloudy-night   \n",
       "\n",
       "        precipIntensity  precipProbability  temperature  apparentTemperature  \\\n",
       "0              0.000000               0.00     0.557537             0.624395   \n",
       "1              0.000000               0.00     0.552286             0.619937   \n",
       "2              0.000000               0.00     0.551200             0.619015   \n",
       "3              0.000000               0.00     0.548755             0.616940   \n",
       "4              0.000000               0.00     0.547850             0.616171   \n",
       "...                 ...                ...          ...                  ...   \n",
       "130982         0.001799               0.03     0.470982             0.550918   \n",
       "130983         0.000846               0.02     0.455319             0.537622   \n",
       "130984         0.000000               0.00     0.443278             0.527400   \n",
       "130985         0.000000               0.00     0.429516             0.515717   \n",
       "130986         0.001799               0.03     0.418470             0.491584   \n",
       "\n",
       "        dewPoint  humidity  pressure  ...    demand  Year  Month  Day  Hour  \\\n",
       "0       0.858447      0.79  0.575804  ...  0.116990  2018      7    1     8   \n",
       "1       0.855708      0.80  0.571210  ...  0.112280  2018      7    1     9   \n",
       "2       0.853181      0.79  0.568147  ...  0.108183  2018      7    1    10   \n",
       "3       0.853813      0.80  0.571210  ...  0.105575  2018      7    1    11   \n",
       "4       0.852970      0.80  0.578867  ...  0.104825  2018      7    1    12   \n",
       "...          ...       ...       ...  ...       ...   ...    ...  ...   ...   \n",
       "130982  0.742241      0.60  0.643185  ...  0.069285  2020      4   26     3   \n",
       "130983  0.747297      0.66  0.650842  ...  0.069285  2020      4   26     4   \n",
       "130984  0.750316      0.70  0.661562  ...  0.069285  2020      4   26     5   \n",
       "130985  0.752142      0.75  0.666156  ...  0.069285  2020      4   26     6   \n",
       "130986  0.754388      0.80  0.667688  ...  0.069285  2020      4   26     7   \n",
       "\n",
       "        day_of_week season  outlier_flag anomaly_flag Flagged_anomaly_outlier  \n",
       "0                 6      3             0            0                       0  \n",
       "1                 6      3             0            0                       0  \n",
       "2                 6      3             0            0                       0  \n",
       "3                 6      3             1            0                       1  \n",
       "4                 6      3             0            0                       0  \n",
       "...             ...    ...           ...          ...                     ...  \n",
       "130982            6      2             0            0                       0  \n",
       "130983            6      2             0            0                       0  \n",
       "130984            6      2             0            0                       0  \n",
       "130985            6      2             0            0                       0  \n",
       "130986            6      2             0            0                       0  \n",
       "\n",
       "[130987 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8303e1f7-69ca-44c9-a998-b3ac9ff274ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['outlier_flag', 'anomaly_flag'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51327d5c-6b74-4664-99df-62cea81f1fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>summary</th>\n",
       "      <th>icon</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>precipProbability</th>\n",
       "      <th>temperature</th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>demand</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>season</th>\n",
       "      <th>Flagged_anomaly_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.557537</td>\n",
       "      <td>0.624395</td>\n",
       "      <td>0.858447</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.575804</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-07-01 08:00:00</td>\n",
       "      <td>la</td>\n",
       "      <td>0.116990</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.552286</td>\n",
       "      <td>0.619937</td>\n",
       "      <td>0.855708</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.571210</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-07-01 09:00:00</td>\n",
       "      <td>la</td>\n",
       "      <td>0.112280</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.551200</td>\n",
       "      <td>0.619015</td>\n",
       "      <td>0.853181</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.568147</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-07-01 10:00:00</td>\n",
       "      <td>la</td>\n",
       "      <td>0.108183</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.548755</td>\n",
       "      <td>0.616940</td>\n",
       "      <td>0.853813</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.571210</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-07-01 11:00:00</td>\n",
       "      <td>la</td>\n",
       "      <td>0.105575</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La_with_demand</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.547850</td>\n",
       "      <td>0.616171</td>\n",
       "      <td>0.852970</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.578867</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-07-01 12:00:00</td>\n",
       "      <td>la</td>\n",
       "      <td>0.104825</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130982</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.470982</td>\n",
       "      <td>0.550918</td>\n",
       "      <td>0.742241</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.643185</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-04-26 03:00:00</td>\n",
       "      <td>seattle</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130983</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.455319</td>\n",
       "      <td>0.537622</td>\n",
       "      <td>0.747297</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.650842</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-04-26 04:00:00</td>\n",
       "      <td>seattle</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130984</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.443278</td>\n",
       "      <td>0.527400</td>\n",
       "      <td>0.750316</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.661562</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-04-26 05:00:00</td>\n",
       "      <td>seattle</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130985</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.429516</td>\n",
       "      <td>0.515717</td>\n",
       "      <td>0.752142</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.666156</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-04-26 06:00:00</td>\n",
       "      <td>seattle</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130986</th>\n",
       "      <td>Seattle_with_demand</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.418470</td>\n",
       "      <td>0.491584</td>\n",
       "      <td>0.754388</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.667688</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-04-26 07:00:00</td>\n",
       "      <td>seattle</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130987 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       City        summary                 icon  \\\n",
       "0            La_with_demand       Overcast               cloudy   \n",
       "1            La_with_demand       Overcast               cloudy   \n",
       "2            La_with_demand       Overcast               cloudy   \n",
       "3            La_with_demand       Overcast               cloudy   \n",
       "4            La_with_demand       Overcast               cloudy   \n",
       "...                     ...            ...                  ...   \n",
       "130982  Seattle_with_demand  Mostly Cloudy    partly-cloudy-day   \n",
       "130983  Seattle_with_demand  Mostly Cloudy  partly-cloudy-night   \n",
       "130984  Seattle_with_demand  Mostly Cloudy  partly-cloudy-night   \n",
       "130985  Seattle_with_demand  Mostly Cloudy  partly-cloudy-night   \n",
       "130986  Seattle_with_demand  Mostly Cloudy  partly-cloudy-night   \n",
       "\n",
       "        precipIntensity  precipProbability  temperature  apparentTemperature  \\\n",
       "0              0.000000               0.00     0.557537             0.624395   \n",
       "1              0.000000               0.00     0.552286             0.619937   \n",
       "2              0.000000               0.00     0.551200             0.619015   \n",
       "3              0.000000               0.00     0.548755             0.616940   \n",
       "4              0.000000               0.00     0.547850             0.616171   \n",
       "...                 ...                ...          ...                  ...   \n",
       "130982         0.001799               0.03     0.470982             0.550918   \n",
       "130983         0.000846               0.02     0.455319             0.537622   \n",
       "130984         0.000000               0.00     0.443278             0.527400   \n",
       "130985         0.000000               0.00     0.429516             0.515717   \n",
       "130986         0.001799               0.03     0.418470             0.491584   \n",
       "\n",
       "        dewPoint  humidity  pressure  ...            datetime     city  \\\n",
       "0       0.858447      0.79  0.575804  ... 2018-07-01 08:00:00       la   \n",
       "1       0.855708      0.80  0.571210  ... 2018-07-01 09:00:00       la   \n",
       "2       0.853181      0.79  0.568147  ... 2018-07-01 10:00:00       la   \n",
       "3       0.853813      0.80  0.571210  ... 2018-07-01 11:00:00       la   \n",
       "4       0.852970      0.80  0.578867  ... 2018-07-01 12:00:00       la   \n",
       "...          ...       ...       ...  ...                 ...      ...   \n",
       "130982  0.742241      0.60  0.643185  ... 2020-04-26 03:00:00  seattle   \n",
       "130983  0.747297      0.66  0.650842  ... 2020-04-26 04:00:00  seattle   \n",
       "130984  0.750316      0.70  0.661562  ... 2020-04-26 05:00:00  seattle   \n",
       "130985  0.752142      0.75  0.666156  ... 2020-04-26 06:00:00  seattle   \n",
       "130986  0.754388      0.80  0.667688  ... 2020-04-26 07:00:00  seattle   \n",
       "\n",
       "          demand  Year  Month  Day Hour  day_of_week season  \\\n",
       "0       0.116990  2018      7    1    8            6      3   \n",
       "1       0.112280  2018      7    1    9            6      3   \n",
       "2       0.108183  2018      7    1   10            6      3   \n",
       "3       0.105575  2018      7    1   11            6      3   \n",
       "4       0.104825  2018      7    1   12            6      3   \n",
       "...          ...   ...    ...  ...  ...          ...    ...   \n",
       "130982  0.069285  2020      4   26    3            6      2   \n",
       "130983  0.069285  2020      4   26    4            6      2   \n",
       "130984  0.069285  2020      4   26    5            6      2   \n",
       "130985  0.069285  2020      4   26    6            6      2   \n",
       "130986  0.069285  2020      4   26    7            6      2   \n",
       "\n",
       "       Flagged_anomaly_outlier  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            1  \n",
       "4                            0  \n",
       "...                        ...  \n",
       "130982                       0  \n",
       "130983                       0  \n",
       "130984                       0  \n",
       "130985                       0  \n",
       "130986                       0  \n",
       "\n",
       "[130987 rows x 28 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99cb743c-e275-4885-88a6-8be867d319b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e04037-e57b-4281-89be-873e18e4c5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
