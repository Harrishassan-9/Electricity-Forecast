{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cc351b9-5f6e-4fcb-9b39-797d7a34a989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Processing: LA\n",
      "📊 Weather data rows: 16574, Unique timestamps: 16574\n",
      "📊 Demand data rows: 16536, Unique timestamps: 16536\n",
      "✅ Records matched on datetime & city: 16526\n",
      "📅 Sample matched timestamps: <DatetimeArray>\n",
      "['2018-07-01 08:00:00', '2018-07-01 09:00:00', '2018-07-01 10:00:00',\n",
      " '2018-07-01 11:00:00', '2018-07-01 12:00:00']\n",
      "Length: 5, dtype: datetime64[ns]\n",
      "💾 Saved: C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\\la_with_demand.csv\n",
      "\n",
      "🔍 Processing: NYC\n",
      "📊 Weather data rows: 16574, Unique timestamps: 16574\n",
      "📊 Demand data rows: 16536, Unique timestamps: 16536\n",
      "✅ Records matched on datetime & city: 16503\n",
      "📅 Sample matched timestamps: <DatetimeArray>\n",
      "['2018-07-02 04:00:00', '2018-07-02 05:00:00', '2018-07-02 06:00:00',\n",
      " '2018-07-02 07:00:00', '2018-07-02 08:00:00']\n",
      "Length: 5, dtype: datetime64[ns]\n",
      "💾 Saved: C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\\nyc_with_demand.csv\n",
      "\n",
      "🔍 Processing: DALLAS\n",
      "📊 Weather data rows: 16574, Unique timestamps: 16574\n",
      "📊 Demand data rows: 16536, Unique timestamps: 16536\n",
      "✅ Records matched on datetime & city: 16503\n",
      "📅 Sample matched timestamps: <DatetimeArray>\n",
      "['2018-07-02 05:00:00', '2018-07-02 06:00:00', '2018-07-02 07:00:00',\n",
      " '2018-07-02 08:00:00', '2018-07-02 09:00:00']\n",
      "Length: 5, dtype: datetime64[ns]\n",
      "💾 Saved: C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\\dallas_with_demand.csv\n",
      "\n",
      "🔍 Processing: HOUSTON\n",
      "📊 Weather data rows: 16574, Unique timestamps: 16574\n",
      "📊 Demand data rows: 16536, Unique timestamps: 16536\n",
      "✅ Records matched on datetime & city: 16503\n",
      "📅 Sample matched timestamps: <DatetimeArray>\n",
      "['2018-07-02 05:00:00', '2018-07-02 06:00:00', '2018-07-02 07:00:00',\n",
      " '2018-07-02 08:00:00', '2018-07-02 09:00:00']\n",
      "Length: 5, dtype: datetime64[ns]\n",
      "💾 Saved: C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\\houston_with_demand.csv\n",
      "\n",
      "🔍 Processing: PHILADELPHIA\n",
      "📊 Weather data rows: 16574, Unique timestamps: 16574\n",
      "📊 Demand data rows: 16536, Unique timestamps: 16536\n",
      "✅ Records matched on datetime & city: 16503\n",
      "📅 Sample matched timestamps: <DatetimeArray>\n",
      "['2018-07-02 04:00:00', '2018-07-02 05:00:00', '2018-07-02 06:00:00',\n",
      " '2018-07-02 07:00:00', '2018-07-02 08:00:00']\n",
      "Length: 5, dtype: datetime64[ns]\n",
      "💾 Saved: C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\\philadelphia_with_demand.csv\n",
      "\n",
      "🔍 Processing: SAN_ANTONIO\n",
      "📊 Weather data rows: 16574, Unique timestamps: 16574\n",
      "📊 Demand data rows: 16536, Unique timestamps: 16536\n",
      "✅ Records matched on datetime & city: 16503\n",
      "📅 Sample matched timestamps: <DatetimeArray>\n",
      "['2018-07-02 05:00:00', '2018-07-02 06:00:00', '2018-07-02 07:00:00',\n",
      " '2018-07-02 08:00:00', '2018-07-02 09:00:00']\n",
      "Length: 5, dtype: datetime64[ns]\n",
      "💾 Saved: C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\\san_antonio_with_demand.csv\n",
      "\n",
      "🔍 Processing: SAN_DIEGO\n",
      "📊 Weather data rows: 16574, Unique timestamps: 16574\n",
      "📊 Demand data rows: 16536, Unique timestamps: 16536\n",
      "✅ Records matched on datetime & city: 16526\n",
      "📅 Sample matched timestamps: <DatetimeArray>\n",
      "['2018-07-01 08:00:00', '2018-07-01 09:00:00', '2018-07-01 10:00:00',\n",
      " '2018-07-01 11:00:00', '2018-07-01 12:00:00']\n",
      "Length: 5, dtype: datetime64[ns]\n",
      "💾 Saved: C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\\san_diego_with_demand.csv\n",
      "\n",
      "🔍 Processing: SAN_JOSE\n",
      "📊 Weather data rows: 16574, Unique timestamps: 16574\n",
      "📊 Demand data rows: 16536, Unique timestamps: 16536\n",
      "✅ Records matched on datetime & city: 16526\n",
      "📅 Sample matched timestamps: <DatetimeArray>\n",
      "['2018-07-01 08:00:00', '2018-07-01 09:00:00', '2018-07-01 10:00:00',\n",
      " '2018-07-01 11:00:00', '2018-07-01 12:00:00']\n",
      "Length: 5, dtype: datetime64[ns]\n",
      "💾 Saved: C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\\san_jose_with_demand.csv\n",
      "\n",
      "🔍 Processing: PHOENIX\n",
      "📊 Weather data rows: 16574, Unique timestamps: 16574\n",
      "📊 Demand data rows: 15960, Unique timestamps: 15960\n",
      "✅ Records matched on datetime & city: 15950\n",
      "📅 Sample matched timestamps: <DatetimeArray>\n",
      "['2018-07-01 08:00:00', '2018-07-01 09:00:00', '2018-07-01 10:00:00',\n",
      " '2018-07-01 11:00:00', '2018-07-01 12:00:00']\n",
      "Length: 5, dtype: datetime64[ns]\n",
      "💾 Saved: C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\\phoenix_with_demand.csv\n",
      "\n",
      "🔍 Processing: SEATTLE\n",
      "📊 Weather data rows: 16574, Unique timestamps: 16574\n",
      "📊 Demand data rows: 15960, Unique timestamps: 15960\n",
      "✅ Records matched on datetime & city: 15950\n",
      "📅 Sample matched timestamps: <DatetimeArray>\n",
      "['2018-07-01 08:00:00', '2018-07-01 09:00:00', '2018-07-01 10:00:00',\n",
      " '2018-07-01 11:00:00', '2018-07-01 12:00:00']\n",
      "Length: 5, dtype: datetime64[ns]\n",
      "💾 Saved: C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\\seattle_with_demand.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Define input and output directories\n",
    "input_dir = r\"C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\"\n",
    "output_dir = r\"C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv_&_with_Demand\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Load demand datasets\n",
    "balance_df = pd.read_csv(os.path.join(input_dir, \"cleaned_balance_data.csv\"))\n",
    "subregion_df = pd.read_csv(os.path.join(input_dir, \"cleaned_subregion_data.csv\"))\n",
    "\n",
    "# Prepare datetime column (no truncation to date)\n",
    "balance_df['datetime'] = pd.to_datetime(balance_df['utc_time'])\n",
    "subregion_df['datetime'] = pd.to_datetime(subregion_df['utc_time'])\n",
    "\n",
    "# Define cities and their data sources\n",
    "cities = {\n",
    "    'la': 'subregion',\n",
    "    'nyc': 'subregion',\n",
    "    'dallas': 'subregion',\n",
    "    'houston': 'subregion',\n",
    "    'philadelphia': 'subregion',\n",
    "    'san_antonio': 'subregion',\n",
    "    'san_diego': 'subregion',\n",
    "    'san_jose': 'subregion',\n",
    "    'phoenix': 'balance',\n",
    "    'seattle': 'balance'\n",
    "}\n",
    "\n",
    "# Cities list and respective demand source\n",
    "city_name_mapping = {\n",
    "    'phoenix': 'phoenix',\n",
    "    'seattle': 'seattle',\n",
    "    'la': 'la',\n",
    "    'nyc': 'nyc',\n",
    "    'dallas': 'dallas',\n",
    "    'houston': 'houston',\n",
    "    'philadelphia': 'philadelphia',\n",
    "    'san_antonio': 'san antonio',\n",
    "    'san_diego': 'san diego',\n",
    "    'san_jose': 'san jose'\n",
    "}\n",
    "\n",
    "merged_data = {}\n",
    "\n",
    "for city, source in cities.items():\n",
    "    print(f\"\\n🔍 Processing: {city.upper()}\")\n",
    "\n",
    "    # Load weather data\n",
    "    try:\n",
    "        weather_df = pd.read_csv(os.path.join(input_dir, f\"{city}.csv\"))\n",
    "        weather_df['datetime'] = pd.to_datetime(weather_df['time'], unit='s')\n",
    "        weather_df['city'] = city_name_mapping[city.lower()]  # Use mapped city name\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️ Weather file {city}.csv not found in {input_dir}.\")\n",
    "        continue\n",
    "\n",
    "    # Get correct demand data for city\n",
    "    demand_city = city_name_mapping[city.lower()]\n",
    "    if source == 'balance':\n",
    "        demand_df = balance_df[balance_df['city'].str.lower() == demand_city]\n",
    "    else:\n",
    "        demand_df = subregion_df[subregion_df['city'].str.lower() == demand_city]\n",
    "\n",
    "    # Check if demand data exists for the city\n",
    "    if demand_df.empty:\n",
    "        print(f\"⚠️ No demand data found for {demand_city} in {source} dataset.\")\n",
    "        continue\n",
    "\n",
    "    # Debug: Check row counts and unique timestamps\n",
    "    print(f\"📊 Weather data rows: {len(weather_df)}, Unique timestamps: {weather_df['datetime'].nunique()}\")\n",
    "    print(f\"📊 Demand data rows: {len(demand_df)}, Unique timestamps: {demand_df['datetime'].nunique()}\")\n",
    "\n",
    "    # Merge on 'datetime' and 'city'\n",
    "    merged = pd.merge(\n",
    "        weather_df,\n",
    "        demand_df[['datetime', 'city', 'demand']],\n",
    "        on=['datetime', 'city'],\n",
    "        how='inner'\n",
    "    )\n",
    "    merged_data[city] = merged\n",
    "\n",
    "    # Report\n",
    "    matched = merged.shape[0]\n",
    "    print(f\"✅ Records matched on datetime & city: {matched}\")\n",
    "    if matched > 0:\n",
    "        print(\"📅 Sample matched timestamps:\", merged['datetime'].unique()[:5])\n",
    "    else:\n",
    "        print(f\"⚠️ No matches found. Check datetime and city name consistency (e.g., '{city}' vs. '{demand_city}').\")\n",
    "\n",
    "    # Save results to the specified directory\n",
    "    if matched > 0:\n",
    "        output_file = os.path.join(output_dir, f\"{city}_with_demand.csv\")\n",
    "        try:\n",
    "            merged.to_csv(output_file, index=False)\n",
    "            print(f\"💾 Saved: {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error saving {output_file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f0fe9d-a107-4f77-ae82-78bcbcd48fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
