{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be55cec-8fa6-4f19-a4f3-f4e2b4ef7805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shubhamkulkarni01/us-top-10-cities-electricity-and-weather-data?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43.0M/43.0M [00:10<00:00, 4.27MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Specify the target directory\n",
    "target_dir = r\"C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\"\n",
    "\n",
    "# Download latest version of the dataset\n",
    "path = kagglehub.dataset_download(\"shubhamkulkarni01/us-top-10-cities-electricity-and-weather-data\")\n",
    "\n",
    "# Create target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Move the downloaded dataset to the target directory\n",
    "shutil.move(path, target_dir)\n",
    "\n",
    "# Construct the new path to the dataset files\n",
    "new_path = os.path.join(target_dir, os.path.basename(path))\n",
    "\n",
    "print(\"Path to dataset files:\", new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe536d7-2cc8-4198-9309-391a4721d9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted dallas.json to dallas.csv\n",
      "Converted houston.json to houston.csv\n",
      "Converted la.json to la.csv\n",
      "Converted nyc.json to nyc.csv\n",
      "Converted philadelphia.json to philadelphia.csv\n",
      "Converted phoenix.json to phoenix.csv\n",
      "Converted san_antonio.json to san_antonio.csv\n",
      "Converted san_diego.json to san_diego.csv\n",
      "Converted san_jose.json to san_jose.csv\n",
      "Converted seattle.json to seattle.csv\n",
      "Copied cleaned_balance_data.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied cleaned_subregion_data.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied cleaned_texas_data.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied dallas.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied EIA930_BALANCE_2018_Jul_Dec.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied EIA930_BALANCE_2019_Jan_Jun.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied EIA930_BALANCE_2019_Jul_Dec.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied EIA930_BALANCE_2020_Jan_Jun.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied EIA930_SUBREGION_2018_Jul_Dec.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied EIA930_SUBREGION_2019_Jan_Jun.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied EIA930_SUBREGION_2019_Jul_Dec.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied EIA930_SUBREGION_2020_Jan_Jun.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied houston.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied la.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied nyc.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied philadelphia.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied phoenix.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied san_antonio.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied san_diego.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied san_jose.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied seattle.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied texas2018.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied texas2019.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n",
      "Copied texas2020.csv to C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# Define input and output directories\n",
    "input_dir = r\"C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset\"\n",
    "output_dir = r\"C:\\Users\\User\\Desktop\\Data Mining\\Project\\Data\\Dataset_in_csv\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Change to the input directory\n",
    "os.chdir(input_dir)\n",
    "\n",
    "# Function to convert a file to CSV\n",
    "def convert_to_csv(file_path, output_csv_path):\n",
    "    if file_path.endswith(('.xls', '.xlsx')):\n",
    "        # Read Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "    elif file_path.endswith(('.json', '.jsonl')):\n",
    "        # Read JSON file (handle JSON Lines if .jsonl)\n",
    "        df = pd.read_json(file_path, lines=file_path.endswith('.jsonl'))\n",
    "    else:\n",
    "        return False  # Not a supported file type\n",
    "    # Save as CSV\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    return True\n",
    "\n",
    "# Find all .xls, .xlsx, .json, and .jsonl files\n",
    "files_to_convert = glob.glob(\"*.xls\") + glob.glob(\"*.xlsx\") + glob.glob(\"*.json\") + glob.glob(\"*.jsonl\")\n",
    "\n",
    "# Convert files to CSV\n",
    "for file in files_to_convert:\n",
    "    # Define the output CSV file path (same name, .csv extension)\n",
    "    csv_file = os.path.splitext(file)[0] + \".csv\"\n",
    "    csv_path = os.path.join(input_dir, csv_file)\n",
    "    \n",
    "    # Convert the file to CSV\n",
    "    if convert_to_csv(file, csv_path):\n",
    "        print(f\"Converted {file} to {csv_file}\")\n",
    "    else:\n",
    "        print(f\"Skipped {file} (unsupported format)\")\n",
    "\n",
    "# Find all CSV files (existing and newly created)\n",
    "csv_files = glob.glob(\"*.csv\")\n",
    "\n",
    "# Copy all CSV files to the output directory\n",
    "for csv_file in csv_files:\n",
    "    src_path = os.path.join(input_dir, csv_file)\n",
    "    dst_path = os.path.join(output_dir, csv_file)\n",
    "    shutil.copy2(src_path, dst_path)\n",
    "    print(f\"Copied {csv_file} to {output_dir}\")\n",
    "\n",
    "# Check if any files were processed\n",
    "if not files_to_convert and not csv_files:\n",
    "    print(\"No files found to convert or copy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642fe9f9-4205-4552-9ba8-4282943c5819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
